{
 "metadata": {
  "name": "",
  "signature": "sha256:cd16729b6b9a5a3fd52954d792e527aebb429b149827decce4102a5b3c7293cf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# ASSIGNMENT 7\n",
      "# Your Name\n",
      "\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import scipy.signal\n",
      "import cv2\n",
      "\n",
      "# Import ORB as SIFT to avoid confusion.\n",
      "try:\n",
      "  from cv2 import ORB as SIFT\n",
      "except ImportError:\n",
      "  try:\n",
      "    from cv2 import SIFT\n",
      "  except ImportError:\n",
      "    try:\n",
      "      SIFT = cv2.ORB_create\n",
      "    except:\n",
      "      raise AttributeError(\"Version of OpenCV(%s) does not have SIFT / ORB.\"\n",
      "                      % cv2.__version__)\n",
      "\n",
      "\n",
      "\"\"\" Assignment 7 - Feature Detection and Matching\n",
      "\n",
      "This file has a number of functions that you need to fill out in order to\n",
      "complete the assignment. Please write the appropriate code, following the\n",
      "instructions on which functions you may or may not use.\n",
      "\n",
      "GENERAL RULES:\n",
      "    1. DO NOT INCLUDE code that saves, shows, displays, writes the image that\n",
      "    you are being passed in. Do that on your own if you need to save the images\n",
      "    but the functions should NOT save the image to file. (This is a problem\n",
      "    for us when grading because running 200 files results a lot of images being\n",
      "    saved to file and opened in dialogs, which is not ideal). Thanks.\n",
      "\n",
      "    2. DO NOT import any other libraries aside from the three libraries that we\n",
      "    provide. You may not import anything else, you should be able to complete\n",
      "    the assignment with the given libraries (and in most cases without them).\n",
      "\n",
      "    3. DO NOT change the format of this file. Do not put functions into classes,\n",
      "    or your own infrastructure. This makes grading very difficult for us. Please\n",
      "    only write code in the allotted region.\n",
      "\"\"\"\n",
      "\n",
      "def findMatchesBetweenImages(image_1, image_2):\n",
      "  \"\"\" Return the top 10 list of matches between two input images.\n",
      "\n",
      "  This function detects and computes SIFT (or ORB) from the input images, and\n",
      "  returns the best matches using the normalized Hamming Distance.\n",
      "\n",
      "  Follow these steps:\n",
      "  1. Compute SIFT keypoints and descriptors for both images\n",
      "  2. Create a Brute Force Matcher, using the hamming distance (and set\n",
      "     crossCheck to true).\n",
      "  3. Compute the matches between both images.\n",
      "  4. Sort the matches based on distance so you get the best matches.\n",
      "  5. Return the image_1 keypoints, image_2 keypoints, and the top 10 matches in\n",
      "     a list.\n",
      "\n",
      "  Note: We encourage you use OpenCV functionality (also shown in lecture) to\n",
      "  complete this function.\n",
      "\n",
      "  Args:\n",
      "    image_1 (numpy.ndarray): The first image (grayscale).\n",
      "    image_2 (numpy.ndarray): The second image. (grayscale).\n",
      "\n",
      "  Returns:\n",
      "    image_1_kp (list): The image_1 keypoints, the elements are of type\n",
      "                       cv2.KeyPoint.\n",
      "    image_2_kp (list): The image_2 keypoints, the elements are of type \n",
      "                       cv2.KeyPoint.\n",
      "    matches (list): A list of matches, length 10. Each item in the list is of\n",
      "                    type cv2.DMatch.\n",
      "\n",
      "  \"\"\"\n",
      "  # matches - type: list of cv2.DMath\n",
      "  matches = None\n",
      "  # image_1_kp - type: list of cv2.KeyPoint items.\n",
      "  image_1_kp = None\n",
      "  # image_1_desc - type: numpy.ndarray of numpy.uint8 values.\n",
      "  image_1_desc = None\n",
      "  # image_2_kp - type: list of cv2.KeyPoint items.\n",
      "  image_2_kp = None\n",
      "  # image_2_desc - type: numpy.ndarray of numpy.uint8 values.\n",
      "  image_2_desc = None\n",
      "\n",
      "  # WRITE YOUR CODE HERE.\n",
      "  orb = cv2.ORB()\n",
      "\n",
      "  image_1_kp, image_1_desc = orb.detectAndCompute(image_1,None)\n",
      "  image_2_kp, image_2_desc = orb.detectAndCompute(image_2,None)\n",
      "\n",
      "\n",
      "  bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
      "\n",
      "  \n",
      "  matches = bf.match(des1,des2)\n",
      "  matches = sorted(matches, key = lambda x:x.distance)[:10]\n",
      "\n",
      "\n",
      "  # We coded the return statement for you. You are free to modify it -- just\n",
      "  # make sure the tests pass.\n",
      "  return image_1_kp, image_2_kp, matches\n",
      "  # END OF FUNCTION.\n",
      "\n",
      "\n",
      "def drawMatches(image_1, image_1_keypoints, image_2, image_2_keypoints, matches):\n",
      "  \"\"\" Draws the matches between the image_1 and image_2.\n",
      "\n",
      "  This function is provided to you for visualization because there were\n",
      "  differences in the OpenCV 3.0.0-alpha implementation of drawMatches and the\n",
      "  2.4.9 version, so we decided to provide the functionality ourselves.\n",
      "\n",
      "  Note: Do not edit this function, it is provided for you for visualization\n",
      "  purposes.\n",
      "\n",
      "  Args:\n",
      "    image_1 (numpy.ndarray): The first image (can be color or grayscale).\n",
      "    image_1_keypoints (list): The image_1 keypoints, the elements are of type\n",
      "                              cv2.KeyPoint.\n",
      "    image_2 (numpy.ndarray): The image to search in (can be color or grayscale).\n",
      "    image_2_keypoints (list): The image_2 keypoints, the elements are of type\n",
      "                              cv2.KeyPoint.\n",
      "\n",
      "  Returns:\n",
      "    output (numpy.ndarray): An output image that draws lines from the input\n",
      "                            image to the output image based on where the\n",
      "                            matching features are.\n",
      "  \"\"\"\n",
      "  # Compute number of channels.\n",
      "  num_channels = 1\n",
      "  if len(image_1.shape) == 3:\n",
      "    num_channels = image_1.shape[2]\n",
      "  # Separation between images.\n",
      "  margin = 10\n",
      "  # Create an array that will fit both images (with a margin of 10 to separate\n",
      "  # the two images)\n",
      "  joined_image = np.zeros((max(image_1.shape[0], image_2.shape[0]),\n",
      "                           image_1.shape[1] + image_2.shape[1] + margin,\n",
      "                           3))\n",
      "  if num_channels == 1:\n",
      "    for channel_idx in range(3):\n",
      "      joined_image[:image_1.shape[0],\n",
      "                   :image_1.shape[1],\n",
      "                   channel_idx] = image_1\n",
      "      joined_image[:image_2.shape[0],\n",
      "                   image_1.shape[1] + margin:,\n",
      "                   channel_idx] = image_2\n",
      "  else:\n",
      "    joined_image[:image_1.shape[0], :image_1.shape[1]] = image_1\n",
      "    joined_image[:image_2.shape[0], image_1.shape[1] + margin:] = image_2\n",
      "\n",
      "  for match in matches:\n",
      "    image_1_point = (int(image_1_keypoints[match.queryIdx].pt[0]),\n",
      "                     int(image_1_keypoints[match.queryIdx].pt[1]))\n",
      "    image_2_point = (int(image_2_keypoints[match.trainIdx].pt[0] + \\\n",
      "                         image_1.shape[1] + margin),\n",
      "                   int(image_2_keypoints[match.trainIdx].pt[1]))\n",
      "\n",
      "    cv2.circle(joined_image, image_1_point, 5, (0, 0, 255), thickness = -1)\n",
      "    cv2.circle(joined_image, image_2_point, 5, (0, 255, 0), thickness = -1)\n",
      "    cv2.line(joined_image, image_1_point, image_2_point, (255, 0, 0), \\\n",
      "             thickness = 3)\n",
      "  return joined_image\n",
      "\n",
      "# If you want to output your image, this basic code should work.\n",
      "# image_1 = cv2.imread(\"images/source/sample/image_1.jpg\")\n",
      "# image_2 = cv2.imread(\"images/source/sample/image_2.jpg\")\n",
      "# kp1, kp2, matches = findMatchesBetweenImages(image_1, image_2)\n",
      "# output = drawMatches(image_1, kp1, image_2, kp2, matches)\n",
      "# cv2.imwrite(\"output.png\", output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# If you want to output your image, this basic code should work.\n",
      "image_1 = cv2.imread(\"images/HawaiiDay.jpg\")\n",
      "image_2 = cv2.imread(\"images/HawaiiNight.jpg\")\n",
      "kp1, kp2, matches = findMatchesBetweenImages(image_1, image_2)\n",
      "output = drawMatches(image_1, kp1, image_2, kp2, matches)\n",
      "cv2.imwrite(\"output.png\", output)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 30,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "image_1 = cv2.imread(\"images/HawaiiDay.jpg\")\n",
      "image_2 = cv2.imread(\"images/HawaiiNight.jpg\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print image_2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[[249 254 255]\n",
        "  [250 255 254]\n",
        "  [254 255 253]\n",
        "  ..., \n",
        "  [253 253 253]\n",
        "  [249 252 255]\n",
        "  [248 251 255]]\n",
        "\n",
        " [[249 254 255]\n",
        "  [250 255 254]\n",
        "  [254 255 253]\n",
        "  ..., \n",
        "  [253 253 253]\n",
        "  [249 252 255]\n",
        "  [248 251 255]]\n",
        "\n",
        " [[249 254 255]\n",
        "  [250 255 254]\n",
        "  [254 255 253]\n",
        "  ..., \n",
        "  [253 253 253]\n",
        "  [249 252 255]\n",
        "  [248 251 255]]\n",
        "\n",
        " ..., \n",
        " [[255 255 255]\n",
        "  [255 255 255]\n",
        "  [255 255 255]\n",
        "  ..., \n",
        "  [254 254 254]\n",
        "  [254 254 254]\n",
        "  [254 254 254]]\n",
        "\n",
        " [[255 255 255]\n",
        "  [255 255 255]\n",
        "  [255 255 255]\n",
        "  ..., \n",
        "  [254 254 254]\n",
        "  [254 254 254]\n",
        "  [254 254 254]]\n",
        "\n",
        " [[255 255 255]\n",
        "  [255 255 255]\n",
        "  [255 255 255]\n",
        "  ..., \n",
        "  [254 254 254]\n",
        "  [254 254 254]\n",
        "  [254 254 254]]]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gray= cv2.cvtColor(image_1,cv2.COLOR_BGR2GRAY)\n",
      "\n",
      "sift = cv2.SIFT()\n",
      "kp = sift.detect(gray,None)\n",
      "img=cv2.drawKeypoints(gray,kp,flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
      "cv2.imwrite('sift_keypoints.jpg',img)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "orb = cv2.ORB()\n",
      "gray1= cv2.cvtColor(image_1,cv2.COLOR_BGR2GRAY)\n",
      "gray2= cv2.cvtColor(image_2,cv2.COLOR_BGR2GRAY)\n",
      "# find the keypoints and descriptors with SIFT\n",
      "kp1, des1 = orb.detectAndCompute(gray1,None)\n",
      "kp2, des2 = orb.detectAndCompute(gray2,None)\n",
      "\n",
      "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
      "\n",
      "# Match descriptors.\n",
      "matches = bf.match(des1,des2)\n",
      "matches = sorted(matches, key = lambda x:x.distance)\n",
      "\n",
      "# Draw first 10 matches.\n",
      "img3 = drawMatches(image_1,kp1,image_2,kp2,matches[:10])\n",
      "\n",
      "cv2.imwrite('sift_keypoints.jpg',img3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 21,
       "text": [
        "True"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "findMatchesBetweenImages(image_1, image_2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}