{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Jun 14 13:21:22 2015\n",
    "\n",
    "@author: jake\n",
    "\"\"\"\n",
    "\n",
    "# ASSIGNMENT 8\n",
    "# Your Name\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "import cv2\n",
    "\n",
    "# Import ORB as SIFT to avoid confusion.\n",
    "try:\n",
    "    from cv2 import ORB as SIFT\n",
    "except ImportError:\n",
    "    try:\n",
    "        from cv2 import SIFT\n",
    "    except ImportError:\n",
    "        try:\n",
    "            SIFT = cv2.ORB_create\n",
    "        except:\n",
    "            raise AttributeError(\"Your OpenCV(%s) doesn't have SIFT / ORB.\"\n",
    "                                 % cv2.__version__)\n",
    "\n",
    "\n",
    "\"\"\" Assignment 8 - Panoramas\n",
    "\n",
    "This file has a number of functions that you need to fill out in order to\n",
    "complete the assignment. Please write the appropriate code, following the\n",
    "instructions on which functions you may or may not use.\n",
    "\n",
    "GENERAL RULES:\n",
    "    1. DO NOT INCLUDE code that saves, shows, displays, writes the image that\n",
    "    you are being passed in. Do that on your own if you need to save the images\n",
    "    but the functions should NOT save the image to file. (This is a problem\n",
    "    for us when grading because running 200 files results a lot of images being\n",
    "    saved to file and opened in dialogs, which is not ideal). Thanks.\n",
    "\n",
    "    2. DO NOT import any other libraries aside from the three libraries that we\n",
    "    provide. You may not import anything else, you should be able to complete\n",
    "    the assignment with the given libraries (and in most cases without them).\n",
    "\n",
    "    3. DO NOT change the format of this file. Do not put functions into classes,\n",
    "    or your own infrastructure. This makes grading very difficult for us. Please\n",
    "    only write code in the allotted region.\n",
    "\"\"\"\n",
    "\n",
    "def getImageCorners(image):\n",
    "    \"\"\" For an input image, return its four corners.\n",
    "\n",
    "    You should be able to do this correctly without instruction. If in doubt,\n",
    "    resort to the testing framework. The order in which you store the corners\n",
    "    does not matter.\n",
    "\n",
    "    Note: The reasoning for the shape of the array can be explained if you look\n",
    "    at the documentation for cv2.perspectiveTransform which we will use on the\n",
    "    output of this function. Since we will apply the homography to the corners\n",
    "    of the image, it needs to be in that format.\n",
    "\n",
    "    Another note: When storing your corners, they are assumed to be in the form\n",
    "    (X, Y) -- keep this in mind and make SURE you get it right.\n",
    "\n",
    "    Args:\n",
    "        image (numpy.ndarray): Input can be a grayscale or color image.\n",
    "\n",
    "    Returns:\n",
    "        corners (numpy.ndarray): Array of shape (4, 1, 2). Type of values in the\n",
    "                                 array is np.float32.\n",
    "    \"\"\"\n",
    "    corners = np.zeros((4, 1, 2), dtype=np.float32)\n",
    "    # WRITE YOUR CODE HERE\n",
    "    corners[0] = [0,0]\n",
    "    corners[1] = [image.shape[0],0]\n",
    "    corners[2] = [0,image.shape[1]]\n",
    "    corners[2] = [image.shape[0],image.shape[1]]\n",
    "\n",
    "    return corners\n",
    "    # END OF FUNCTION\n",
    "\n",
    "def findMatchesBetweenImages(image_1, image_2, num_matches):\n",
    "    \"\"\" Return the top list of matches between two input images.\n",
    "\n",
    "    Note: You will not be graded for this function. This function is almost\n",
    "    identical to the function in Assignment 7 (we just parametrized the number\n",
    "    of matches). We expect you to use the function you wrote in A7 here. We will\n",
    "    also release a solution for how to do this after A7 submission has closed.\n",
    "\n",
    "    If your code from A7 was wrong, don't worry, you will not lose points in\n",
    "    this assignment because your A7 code was wrong (hence why we will provide a\n",
    "    solution for you after A7 closes).\n",
    "\n",
    "    This function detects and computes SIFT (or ORB) from the input images, and\n",
    "    returns the best matches using the normalized Hamming Distance through brute\n",
    "    force matching.\n",
    "\n",
    "    Args:\n",
    "        image_1 (numpy.ndarray): The first image (grayscale).\n",
    "        image_2 (numpy.ndarray): The second image. (grayscale).\n",
    "        num_matches (int): The number of desired matches. If there are not\n",
    "                           enough, return as many matches as you can.\n",
    "\n",
    "    Returns:\n",
    "        image_1_kp (list): The image_1 keypoints, the elements are of type\n",
    "                           cv2.KeyPoint.\n",
    "        image_2_kp (list): The image_2 keypoints, the elements are of type \n",
    "                           cv2.KeyPoint.\n",
    "        matches (list): A list of matches, length 'num_matches'. Each item in \n",
    "                        the list is of type cv2.DMatch. If there are less \n",
    "                        matches than num_matches, this function will return as\n",
    "                        many as it can.\n",
    "\n",
    "    \"\"\"\n",
    "    # matches - type: list of cv2.DMath\n",
    "    # matches - type: list of cv2.DMath\n",
    "\n",
    "\n",
    "\n",
    "    # COPY YOUR CODE FROM A7 HERE.\n",
    "    matches = None\n",
    "    # image_1_kp - type: list of cv2.KeyPoint items.\n",
    "    image_1_kp = None\n",
    "    # image_1_desc - type: numpy.ndarray of numpy.uint8 values.\n",
    "    image_1_desc = None\n",
    "    # image_2_kp - type: list of cv2.KeyPoint items.\n",
    "    image_2_kp = None\n",
    "    # image_2_desc - type: numpy.ndarray of numpy.uint8 values.\n",
    "    image_2_desc = None\n",
    "\n",
    "    # WRITE YOUR CODE HERE.\n",
    "    sift = SIFT()\n",
    "    image_1_kp, image_1_desc = sift.detectAndCompute(image_1, None)\n",
    "    image_2_kp, image_2_desc = sift.detectAndCompute(image_2, None)\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "    matches = bf.match(image_1_desc,image_2_desc)\n",
    "    matches = sorted(matches, key = lambda x:x.distance)\n",
    "    matches = matches[:num_matches]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return image_1_kp, image_2_kp, matches\n",
    "  # END OF FUNCTION.\n",
    "\n",
    "def findHomography(image_1_kp, image_2_kp, matches):\n",
    "    \"\"\" Returns the homography between the keypoints of image 1, image 2, and\n",
    "        its matches.\n",
    "\n",
    "    Follow these steps:\n",
    "        1. Iterate through matches and:\n",
    "            1a. Get the x, y location of the keypoint for each match. Look up\n",
    "                the documentation for cv2.DMatch. Image 1 is your query image,\n",
    "                and Image 2 is your train image. Therefore, to find the correct\n",
    "                x, y location, you index into image_1_kp using match.queryIdx,\n",
    "                and index into image_2_kp using match.trainIdx. The x, y point\n",
    "                is stored in each keypoint (look up documentation).\n",
    "            1b. Set the keypoint 'pt' to image_1_points and image_2_points, it\n",
    "                should look similar to this inside your loop:\n",
    "                    image_1_points[match_idx] = image_1_kp[match.queryIdx].pt\n",
    "                    # Do the same for image_2 points.\n",
    "\n",
    "        2. Call cv2.findHomography and pass in image_1_points, image_2_points,\n",
    "           use method=cv2.RANSAC and ransacReprojThreshold=5.0. I recommend\n",
    "           you look up the documentation on cv2.findHomography to better\n",
    "           understand what these parameters mean.\n",
    "        3. cv2.findHomography returns two values, the homography and a mask.\n",
    "           Ignore the mask, and simply return the homography.\n",
    "\n",
    "    Args:\n",
    "        image_1_kp (list): The image_1 keypoints, the elements are of type\n",
    "                           cv2.KeyPoint.\n",
    "        image_2_kp (list): The image_2 keypoints, the elements are of type \n",
    "                           cv2.KeyPoint.\n",
    "        matches (list): A list of matches. Each item in the list is of type\n",
    "                        cv2.DMatch.\n",
    "    Returns:\n",
    "        homography (numpy.ndarray): A 3x3 homography matrix. Each item in\n",
    "                                    the matrix is of type numpy.float64.\n",
    "    \"\"\"\n",
    "    \n",
    "    image_1_points = np.zeros((len(matches), 1, 2), dtype=np.float32)\n",
    "    image_2_points = np.zeros((len(matches), 1, 2), dtype=np.float32)\n",
    "    i = 0\n",
    "    for DMatch in matches:\n",
    "        \n",
    "        image_1_points[i] = image_1_kp[DMatch.queryIdx].pt\n",
    "        image_2_points[i] = image_2_kp[DMatch.trainIdx].pt\n",
    "        i +=1        \n",
    "    statement,mask = cv2.findHomography(image_1_points,image_2_points,method= cv2.RANSAC ,ransacReprojThreshold=5)    \n",
    "    # WRITE YOUR CODE HERE.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Replace this return statement with the homography.\n",
    "    return statement\n",
    "    # END OF FUNCTION\n",
    "\n",
    "def blendImagePair(warped_image, image_2, point):\n",
    "    \"\"\" This is the blending function. We provide a basic implementation of\n",
    "    this function that we would like you to replace.\n",
    "\n",
    "    This function takes in an image that has been warped and an image that needs\n",
    "    to be inserted into the warped image. Lastly, it takes in a point where the\n",
    "    new image will be inserted.\n",
    "\n",
    "    The current method we provide is very simple, it pastes in the image at the\n",
    "    point. We want you to replace this and blend between the images.\n",
    "\n",
    "    We want you to be creative. The most common implementation would be to take\n",
    "    the average between image 1 and image 2 only for the pixels that overlap.\n",
    "    That is just a starting point / suggestion but you are encouraged to use\n",
    "    other approaches.\n",
    "\n",
    "    Args:\n",
    "        warped_image (numpy.ndarray): The image provided by cv2.warpPerspective.\n",
    "        image_2 (numpy.ndarray): The image to insert into the warped image.\n",
    "        point (numpy.ndarray): The point (x, y) to insert the image at.\n",
    "\n",
    "    Returns:\n",
    "        image: The warped image with image_2 blended into it.\n",
    "    \"\"\"\n",
    "    output_image = np.copy(warped_image)\n",
    "    blending_mask = np.zeros(output_image.shape[:2])\n",
    "\n",
    "    # REPLACE THIS WITH YOUR BLENDING CODE.\n",
    "    output_image[point[1]:point[1] + image_2.shape[0],\n",
    "                 point[0]:point[0] + image_2.shape[1]] = image_2\n",
    "\n",
    "\n",
    "    for y in range(image_2.shape[0]):\n",
    "        for x  in range(image_2.shape[1]):\n",
    "            if not (np.equal(warped_image[point[1] +y,point[0]+x],np.array([0,0,0])).all()):\n",
    "\n",
    "                output_image[point[1]+y, point[0]+x] = (np.uint16(image_2[y,x])+\n",
    "                                                        np.uint16(warped_image[point[1]+y,point[0]+x]))/2\n",
    "\n",
    "                        \n",
    "    \n",
    "    return output_image\n",
    "    # END OF FUNCTION\n",
    "\n",
    "def warpImagePair(image_1, image_2, homography):\n",
    "    \"\"\" Warps image 1 so it can be blended with image 2 (stitched).\n",
    "\n",
    "    Follow these steps:\n",
    "        1. Obtain the corners for image 1 and image 2 using the function you\n",
    "        wrote above.\n",
    "        \n",
    "        2. Transform the perspective of the corners of image 1 by using the\n",
    "        image_1_corners and the homography to obtain the transformed corners.\n",
    "        \n",
    "        Note: Now we know the corners of image 1 and image 2. Out of these 8\n",
    "        points (the transformed corners of image 1 and the corners of image 2),\n",
    "        we want to find the minimum x, maximum x, minimum y, and maximum y. We\n",
    "        will need this when warping the perspective of image 1.\n",
    "\n",
    "        3. Join the two corner arrays together (the transformed image 1 corners,\n",
    "        and the image 2 corners) into one array of size (8, 1, 2).\n",
    "\n",
    "        4. For the first column of this array, find the min and max. This will\n",
    "        be your minimum and maximum X values. Store into x_min, x_max.\n",
    "\n",
    "        5. For the second column of this array, find the min and max. This will\n",
    "        be your minimum and maximum Y values. Store into y_min, y_max.\n",
    "\n",
    "        6. Create a translation matrix that will shift the image by the required\n",
    "        x_min and y_min (should be a numpy.ndarray). This looks like this:\n",
    "            [[1, 0, -1 * x_min],\n",
    "             [0, 1, -1 * y_min],\n",
    "             [0, 0, 1]]\n",
    "\n",
    "        Note: We'd like you to explain the reasoning behind multiplying the\n",
    "        x_min and y_min by negative 1 in your writeup.\n",
    "\n",
    "        7. Compute the dot product of your translation matrix and the homography\n",
    "        in order to obtain the homography matrix with a translation.\n",
    "\n",
    "        8. Then call cv2.warpPerspective. Pass in image 1, the dot product of\n",
    "        the matrix computed in step 6 and the passed in homography and a vector\n",
    "        that will fit both images, since you have the corners and their max and\n",
    "        min, you can calculate it as (x_max - x_min, y_max - y_min).\n",
    "\n",
    "        9. To finish, you need to blend both images. We have coded the call to\n",
    "        the blend function for you.\n",
    "\n",
    "    Args:\n",
    "        image_1 (numpy.ndarray): Left image.\n",
    "        image_2 (numpy.ndarray): Right image.\n",
    "        homography (numpy.ndarray): 3x3 matrix that represents the homography\n",
    "                                    from image 1 to image 2.\n",
    "\n",
    "    Returns:\n",
    "        output_image (numpy.ndarray): The stitched images.\n",
    "    \"\"\"\n",
    "    # Store the result of cv2.warpPerspective in this variable.\n",
    "    warped_image = None\n",
    "    # The minimum and maximum values of your corners.\n",
    "    x_min = 0\n",
    "    y_min = 0\n",
    "    x_max = 0\n",
    "    y_max = 0\n",
    "\n",
    "    # WRITE YOUR CODE HERE\n",
    "    leftUp1 = np.array([[0],[0],[1]])\n",
    "    leftUp2 = np.dot(homography,leftUp1)\n",
    "    leftUp2 = np.int16(leftUp2/leftUp2[2])\n",
    "    rightUp1 = np.array([[image_2.shape[0]],[0],[1]])  \n",
    "    rightUp2 = np.dot(homography,rightUp1)\n",
    "    rightUp2 = np.int16(rightUp2 / rightUp2[2])\n",
    "    leftDown1 = np.array([[0],[image_2.shape[0]],[1]])\n",
    "    leftDown2 = np.dot(homography,leftDown1)\n",
    "    leftDown2 = np.int16(leftDown2/leftDown2[2])\n",
    "    rightDown1 = np.array([[image_2.shape[1]],[image_2.shape[0]],[1]])\n",
    "    rightDown2 = np.dot(homography,rightDown1)\n",
    "    rightDown2 = np.int16(rightDown2/rightDown2[2])\n",
    "\n",
    "    x_min = np.min([leftUp1[0],leftUp2[0],leftDown1[0],leftDown2[0]])\n",
    "    x_max = np.max([rightUp1[0],rightUp2[0],rightDown1[0],rightDown2[0]])\n",
    "    y_min = np.min([leftUp1[1],leftUp2[1],rightUp1[1],rightUp2[1]])\n",
    "    y_max = np.max([leftDown1[1],leftDown2[1],rightDown1[1],rightDown2[1]])\n",
    "    translation = np.array([[1, 0, -1 * x_min],[0, 1, -1 * y_min],[0, 0, 1]])\n",
    "    transHomo = np.dot(translation , homography)\n",
    "\n",
    "    warped_image= cv2.warpPerspective(image_1,transHomo,(x_max - x_min, y_max - y_min))\n",
    "\n",
    "    # END OF CODING\n",
    "\n",
    "    output_image = blendImagePair(warped_image, image_2,\n",
    "                                  (-1 * x_min, -1 * y_min))\n",
    "    return output_image\n",
    "\n",
    "\n",
    "# Some simple testing.\n",
    "#image_1 = cv2.imread(\"images/source/panorama_1/1.jpg\")\n",
    "#image_2 = cv2.imread(\"images/source/panorama_1/2.jpg\")\n",
    "#image_3 = cv2.imread(\"images/source/panorama_1/3.jpg\")\n",
    "#image_1_kp, image_2_kp, matches = findMatchesBetweenImages(image_1, image_2,20)\n",
    "                                                       \n",
    "#homography = findHomography(image_1_kp, image_2_kp, matches)\n",
    "#result = warpImagePair(image_1, image_2, homography)\n",
    "\n",
    "#image_1_kp, image_2_kp, matches = findMatchesBetweenImages( result,image_3,20)\n",
    "                                                       \n",
    "\n",
    "#homography = findHomography(image_1_kp, image_2_kp, matches)\n",
    "#result = warpImagePair( result,result2, homography)\n",
    "#cv2.imwrite(\"images/output/panorama_3_result.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_1 = cv2.imread(\"images/source/zen/zen1.jpg\")\n",
    "image_2 = cv2.imread(\"images/source/zen/zen2.jpg\")\n",
    "image_3 = cv2.imread(\"images/source/zen/zen3.jpg\")\n",
    "image_4 = cv2.imread(\"images/source/zen/zen4.jpg\")\n",
    "image_5 = cv2.imread(\"images/source/zen/zen5.jpg\")\n",
    "image_6 = cv2.imread(\"images/source/zen/zen6.jpg\")\n",
    "image_1_kp, image_2_kp, matches = findMatchesBetweenImages(image_1, image_2,50)\n",
    "                                                       \n",
    "homography = findHomography(image_1_kp, image_2_kp, matches)\n",
    "result = warpImagePair(image_1, image_2, homography)\n",
    "\n",
    "image_1_kp, image_2_kp, matches = findMatchesBetweenImages( result,image_3,50)\n",
    "                                                       \n",
    "homography = findHomography(image_1_kp, image_2_kp, matches)\n",
    "result = warpImagePair( result,image_3, homography)\n",
    "\n",
    "#cv2.imwrite(\"images/output/zen_4_result.jpg\", result)\n",
    "image_1_kp, image_2_kp, matches = findMatchesBetweenImages( result,image_4,50)\n",
    "                                                       \n",
    "homography = findHomography(image_1_kp, image_2_kp, matches)\n",
    "result = warpImagePair( result,image_4, homography)\n",
    "cv2.imwrite(\"images/output/zen_3_result.jpg\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
